{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723d9fc3-a52f-49ca-b93f-1931e37dd310",
   "metadata": {},
   "source": [
    "# Bereitstellen der Pakete und Funktionen\n",
    "Führen Sie den unten stehenden Code mit **strg + Enter** aus um alle notwendigen Zusatzpakete und Funktionen verfügbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55440c4-20d4-4048-80fe-619d89417a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported packages\n",
    "import pandas as pd # used to handle csv- or excel files as a dataframe (table object)\n",
    "import numpy as np # used for basic mathematical operations\n",
    "import matplotlib.pyplot as plt # package for basic data plotting\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "import seaborn as sns # additional package with more plotting options based on pyplot\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "# from here code for more complexe plotting functions\n",
    "def _resolve_column(df: pd.DataFrame, col):\n",
    "    \"\"\"Resolve a column specifier for flat or MultiIndex columns.\n",
    "    - col can be None, a tuple (MultiIndex), or a string.\n",
    "    - Exact matches are preferred. If not found and df has MultiIndex,\n",
    "      try to find columns where any level equals the string.\n",
    "    \"\"\"\n",
    "   \n",
    "    if col is None:\n",
    "        return None, None  # (series, display_name)\n",
    "    # tuple (explicit MultiIndex)\n",
    "    if isinstance(col, tuple):\n",
    "        if col in df.columns:\n",
    "            return df[col], \" - \".join(map(str, col))\n",
    "        raise KeyError(f\"Column tuple {col} not found in DataFrame columns.\")\n",
    "    # string case\n",
    "    # direct exact match (flat columns)\n",
    "    if col in df.columns:\n",
    "        return df[col], str(col)\n",
    "    # if MultiIndex, try exact match on any level\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # exact level match\n",
    "        matches = [c for c in df.columns if any(str(level) == col for level in c)]\n",
    "        if len(matches) == 1:\n",
    "            return df[matches[0]], \" - \".join(map(str, matches[0]))\n",
    "        if len(matches) > 1:\n",
    "            # prefer a match where top-level equals col\n",
    "            top_matches = [c for c in matches if str(c[0]) == col]\n",
    "            chosen = top_matches[0] if top_matches else matches[0]\n",
    "            print(f\"Multiple columns match '{col}', using {chosen}.\")\n",
    "            return df[chosen], \" - \".join(map(str, chosen))\n",
    "        # try substring match (e.g., user passes 'PC 1' and column is ('PCA','PC 1'))\n",
    "        substr_matches = [c for c in df.columns if any(col in str(level) for level in c)]\n",
    "        if len(substr_matches) >= 1:\n",
    "            chosen = substr_matches[0]\n",
    "            print(f\"No exact match for '{col}', using first substring match {chosen}.\")\n",
    "            return df[chosen], \" - \".join(map(str, chosen))\n",
    "    # fallback: try substring in flat columns\n",
    "    flat_sub = [c for c in df.columns if col in str(c)]\n",
    "    if len(flat_sub) >= 1:\n",
    "        chosen = flat_sub[0]\n",
    "        print(f\"No exact match for '{col}', using first flat substring match {chosen}.\")\n",
    "        return df[chosen], str(chosen)\n",
    "    raise KeyError(f\"Column '{col}' not found in DataFrame columns.\")\n",
    "\n",
    "def plot_dataframe(df: pd.DataFrame,\n",
    "                   x,\n",
    "                   y,\n",
    "                   z=None,\n",
    "                   hue=None,\n",
    "                   figsize=(9, 6),\n",
    "                   palette=None,\n",
    "                   point_size=40,\n",
    "                   alpha=0.9,\n",
    "                   cmap=\"viridis\",\n",
    "                   title=None):\n",
    "    \"\"\"\n",
    "    Flexible plotting for DataFrame: automatic 2D/3D scatter depending on z.\n",
    "    x, y, z, hue can be strings or tuples (for MultiIndex). If z is None -> 2D.\n",
    "    Returns (fig, ax).\n",
    "    \"\"\"\n",
    "    # Resolve columns and display names\n",
    "    X, x_label = _resolve_column(df, x)\n",
    "    Y, y_label = _resolve_column(df, y)\n",
    "    Z, z_label = _resolve_column(df, z) if z is not None else (None, None)\n",
    "    H, h_label = _resolve_column(df, hue) if hue is not None else (None, None)\n",
    "\n",
    "    if X is None or Y is None:\n",
    "        raise ValueError(\"x and y must be provided and resolvable to DataFrame columns.\")\n",
    "\n",
    "    x_vals = X.values\n",
    "    y_vals = Y.values\n",
    "    z_vals = Z.values if Z is not None else None\n",
    "    hue_vals = H.values if H is not None else None\n",
    "\n",
    "    is_3d = z_vals is not None\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if is_3d:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    else:\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "    # No hue: single color\n",
    "    if hue_vals is None:\n",
    "        color = sns.color_palette()[0]\n",
    "        if is_3d:\n",
    "            sc = ax.scatter(x_vals, y_vals, z_vals, s=point_size, alpha=alpha, color=color)\n",
    "        else:\n",
    "            sc = ax.scatter(x_vals, y_vals, s=point_size, alpha=alpha, color=color)\n",
    "    else:\n",
    "        # Determine whether hue is numeric or categorical.\n",
    "        # If dtype is object or string-like -> categorical.\n",
    "        if pd.api.types.is_numeric_dtype(H):\n",
    "            # continuous hue\n",
    "            if is_3d:\n",
    "                # 3D scatter with continuous color: map to RGBA\n",
    "                norm = plt.Normalize(np.nanmin(hue_vals), np.nanmax(hue_vals))\n",
    "                cmap_obj = plt.get_cmap(cmap)\n",
    "                colors = cmap_obj(norm(hue_vals))\n",
    "                sc = ax.scatter(x_vals, y_vals, z_vals, c=colors, s=point_size, alpha=alpha)\n",
    "                # create a ScalarMappable for colorbar\n",
    "                mappable = plt.cm.ScalarMappable(norm=norm, cmap=cmap_obj)\n",
    "                mappable.set_array(hue_vals)\n",
    "                cbar = fig.colorbar(mappable, ax=ax, pad=0.1)\n",
    "                cbar.set_label(h_label or str(hue))\n",
    "            else:\n",
    "                sc = ax.scatter(x_vals, y_vals, c=hue_vals, cmap=cmap, s=point_size, alpha=alpha)\n",
    "                cbar = fig.colorbar(sc, ax=ax, pad=0.1)\n",
    "                cbar.set_label(h_label or str(hue))\n",
    "        else:\n",
    "            # categorical hue (strings or objects)\n",
    "            categories, uniques = pd.factorize(hue_vals)\n",
    "            n_cats = len(uniques)\n",
    "            if palette is None:\n",
    "                palette = sns.color_palette(n_colors=n_cats)\n",
    "            colors = [palette[i % len(palette)] for i in categories]\n",
    "            if is_3d:\n",
    "                sc = ax.scatter(x_vals, y_vals, z_vals, c=colors, s=point_size, alpha=alpha)\n",
    "            else:\n",
    "                sc = ax.scatter(x_vals, y_vals, c=colors, s=point_size, alpha=alpha)\n",
    "            # legend\n",
    "            handles = []\n",
    "            for i, lab in enumerate(uniques):\n",
    "                handles.append(plt.Line2D([], [], marker='o', color=palette[i % len(palette)], linestyle='', markersize=6))\n",
    "            ax.legend(handles, uniques, title=(h_label or str(hue)), bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(x_label or str(x))\n",
    "    ax.set_ylabel(y_label or str(y))\n",
    "    if is_3d:\n",
    "        ax.set_zlabel(z_label or str(z))\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d59355-a048-42cd-b426-ade3de430e0b",
   "metadata": {},
   "source": [
    "# Importieren der Daten\n",
    "Importieren Sie mit dem unten stehenden Codeabschnitt _(Anpassungen des Codes sind nicht notwendig)_ die Daten aus dem CSV-Ordner in ein Pandas-DataFrame. Nach der Ausführung wird das DataFrame als Tabelle unterhalb des Codeblocks angezeigt. Die Daten bestehen aus 14 Spalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ac4b0-a68c-4745-aed5-68fd3c04351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== dont change paramter from here ===#\n",
    "# creating data frame from nanoindendation data in csv folder\n",
    "df = pd.read_csv(\"Data/CSV/OriginalData.csv\", # file path\n",
    "                header = [0,1], # number of rows for column heads\n",
    "                sep = \";\", # seperator between columns\n",
    "                decimal = \",\" # decimal komma or decimal point\n",
    "                )\n",
    "\n",
    "# Set Indent column as Index\n",
    "df.index = df[(\"Unnamed: 0_level_0\",\"Unnamed: 0_level_1\")]\n",
    "df = df.drop((\"Unnamed: 0_level_0\",\"Unnamed: 0_level_1\"), axis=1)\n",
    "\n",
    "#visualization of the data structure\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856283d8-e989-431d-8f67-923ecd73cace",
   "metadata": {},
   "source": [
    "# Plotten der mechanischen Daten\n",
    "Mit der Ausführung des untenstehenden Codeblocks werden die mechanisch relevanten Daten als Mapping dargestellt.  \n",
    "- Mit den `marker_options` und `colormap` können Sie die Darstellung des Plots beeinflussen.  \n",
    "- Mit `indent_position = \"real\"` oder `\"ideal\"` legen Sie fest, ob die mechanischen Daten anhand ihrer Koordinaten aus der Rasterkraftmikroskopie oder aus den Daten der Nanoindentierung geplottet werden sollen.  \n",
    "- Mit `data_left_plot` und `data_right_plot` können Sie festlegen, welche Spalten des DataFrames geplottet werden sollen.\n",
    "\n",
    "**Frage:**  \n",
    "Können Sie beim Vergleich beider Plots erkennen, welche Indents eine Gruppe bilden könnten?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2bc77-e0bc-4c95-aeca-56fdba878c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === change parameter from here === #\n",
    "\n",
    "#marker options\n",
    "marker_shape = \"s\" #<-- \"s\" for squares, \">\" for triangles\n",
    "marker_size = 85 # setting the size of the markers\n",
    "marker_tranparency = 0.75 # setting the transparency of the markers\n",
    "\n",
    "#change the colormap of the plots\n",
    "colormap = \"crest_r\" #<-- \"viridis\", \"cividis\", \"inferno\" ,\"magma\", \"plasma\", \"rocket\", \"flare\", \"crest\", \"copper\"\n",
    "\n",
    "#choosing between ideal indent position and real indent positions\n",
    "indent_position = \"real\" # <-- \"real\" or \"ideal\"\n",
    "\n",
    "#selecting columns for plotting\n",
    "data_left_plot = (\"HARDNESS GPa\",\"mean\")\n",
    "data_right_plot = (\"MODULUS GPa\",\"mean\")\n",
    "# ========================= #\n",
    "\n",
    "#=== dont change paramter from here ===#\n",
    "\n",
    "#image size\n",
    "image_width_cm = 15 #change value to alter the image size\n",
    "image_height_cm = 15 # change value to alter the image size\n",
    "\n",
    "#Atomic Force Microscopy Mapping of Indentationmapping\n",
    "background_image = plt.imread(\"Data/Images/BackGround.png\")\n",
    "dx,dy = -2.5,-3.2 #parameter for adjusting the background image\n",
    "range_um = 50 # parameter for adjusting the background image\n",
    "\n",
    "# automatical column selection for indent position\n",
    "if indent_position == \"real\":\n",
    "    x = (\"x\",\"real\") # defining x axis\n",
    "    y = (\"y\",\"real\") # defining y axis\n",
    "elif indent_position ==\"ideal\":\n",
    "    x = (\"x\",\"absolut\") # defining x axis\n",
    "    y = (\"y\",\"absolut\") # defining x axis\n",
    "\n",
    "#creating a figure object\n",
    "fig, ax = plt.subplots(nrows = 1,\n",
    "                       ncols = 2, #3 images next to each other\n",
    "                       sharey=True)\n",
    "\n",
    "\n",
    "fig.set_dpi(600) # increasing the resolution of the plot\n",
    "fig.set_size_inches(image_width_cm/2.5,image_height_cm/2.54) #calcuating image size\n",
    "\n",
    "# hardness plot \n",
    "sns.scatterplot(data = df,\n",
    "                x = x,\n",
    "                y = y,\n",
    "                hue = data_left_plot,\n",
    "                ax = ax[0], #left plot\n",
    "                marker = marker_shape, #square marker\n",
    "                palette = sns.color_palette(colormap,as_cmap = True), # defining the color plaette\n",
    "                s = marker_size, # marker size\n",
    "                edgecolor = None, # remove the outline of the markers\n",
    "                alpha = marker_tranparency , # transparence of the markers infill\n",
    "               )\n",
    "\n",
    "if indent_position == \"real\":\n",
    "    ax[0].imshow(background_image,\n",
    "                 extent=[dx,range_um+dx,dy,range_um+dy],\n",
    "                 aspect='equal',\n",
    "                 zorder=-1,\n",
    "                 origin = \"upper\"\n",
    "                )\n",
    "\n",
    "#modulus plot\n",
    "sns.scatterplot(data = df,\n",
    "                x = x,\n",
    "                y = y,\n",
    "                hue = data_right_plot,\n",
    "                ax = ax[1], #middle plot\n",
    "                marker = marker_shape, #square marker\n",
    "                palette = sns.color_palette(colormap,as_cmap = True), # defining the color plaette\n",
    "                s = marker_size, # marker size\n",
    "                edgecolor = None, # remove the outline of the markers\n",
    "                alpha = marker_tranparency , # transparence of the markers infill\n",
    "                )\n",
    "\n",
    "if indent_position == \"real\":\n",
    "    ax[1].imshow(background_image,\n",
    "                 extent=[dx,range_um+dx,dy,range_um+dy],\n",
    "                 aspect='equal',\n",
    "                 zorder=-1,\n",
    "                 origin = \"upper\"\n",
    "                )\n",
    "\n",
    "for item in ax:\n",
    "    item.set_aspect(\"equal\") # ensure äquidistance on x and y axis\n",
    "    sns.move_legend(loc = \"lower center\", bbox_to_anchor = (0.5,1), obj = item) # move legend above the corresponding plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797dc114-730b-40e4-b6e6-1a4b5210a5ea",
   "metadata": {},
   "source": [
    "# Clustering nach KMeans\n",
    "Durch Ausführen des folgenden Codeblocks werden die Daten des DataFrames analysiert und die Indents bezüglich ihrer mechanischen Kennwerte in Gruppen eingeteilt. Hierfür wird im folgenden Beispiel der KMeans-Algorithmus verwendet.\n",
    "\n",
    "KMeans ist ein sogenannter **Clustering-Algorithmus**. Er wird verwendet, um Datenpunkte automatisch in Gruppen (sogenannte *Cluster*) einzuteilen – und zwar **ohne dass man vorher wissen muss, welche Gruppen es gibt**. Das macht KMeans zu einem typischen Verfahren des *unüberwachten Lernens*. Eine wichtige Vorgabe für den KMeans-Algorithmus ist die Anzahl der Cluster.\n",
    "\n",
    "**Ablauf von KMeans**\n",
    "1. Es werden zufällig Clusterzentren initialisiert.\n",
    "2. Jeder Datenpunkt wird dem nächstgelegenen Zentrum zugewiesen.\n",
    "3. Die Clusterzentren werden neu berechnet – als Mittelwert aller zugehörigen Punkte.\n",
    "4. Die Schritte 2 und 3 wiederholen sich, bis sich die Clusterzuweisungen nicht mehr ändern oder ein Abbruchkriterium erreicht ist.\n",
    "\n",
    "**Wichtige Parameter**\n",
    "- `n_clusters` definiert die Anzahl der Gruppen, in die sich die Daten einteilen lassen.  \n",
    "- `feature_set` definiert, welche Spalten des DataFrames für die Gruppierung berücksichtigt werden sollen.\n",
    "\n",
    "**Hinweis**  \n",
    "Stark korrelierende Daten (z. B. Härte in HV und Härte in GPa) sowie nicht physikalische Daten (x-, y-Koordinaten) können die Ergebnisse stark verzerren. Es ist ratsam, dem KMeans-Algorithmus nur für die Fragestellung _(Welche Phasen liegen vor?)_ relevante Daten zu übergeben.  \n",
    "Nach der Ausführung des Codes wird dem DataFrame eine neue Spalte `(\"KMeans\", \"Label\")` hinzugefügt. Diese enthält für jeden Indent die Information, zu welcher Gruppe er gehört.\n",
    "\n",
    "**Nutzen Sie für die Übung `n_clusters = 4` oder höher.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53f17d-3d9f-4136-9f6b-574102336951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === change parameter from here ===\n",
    "n_clusters = 4  # number of clusters\n",
    "feature_set = df[[\n",
    "                    (\"HARDNESS GPa\",\"mean\"),\n",
    "                    (\"MODULUS GPa\",\"mean\"),\n",
    "                    (\"y\",\"real\"),\n",
    "                    (\"y\",\"real\")\n",
    "                ]].copy()\n",
    "#=========================#\n",
    "\n",
    "#=== dont change paramter from here ===#\n",
    "\n",
    "\n",
    "# using the feature set defind\" \n",
    "X_kmeans = feature_set.copy().dropna()\n",
    "\n",
    "# KMeans calculations \n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42)\n",
    "labels = kmeans.fit_predict(X_kmeans).astype(int)\n",
    "\n",
    "# using strings for labelings instaed of numbers\n",
    "#label_names = [f\"Cluster {i+1}\" for i in labels]\n",
    "labels = pd.DataFrame(labels, index=X_kmeans.index)\n",
    "\n",
    "# creating MultiIndex colum name for joining labels_df with df\n",
    "#labels_df.columns = pd.MultiIndex.from_tuples([('KMeans', 'Label')])\n",
    "labels.columns = pd.MultiIndex.from_tuples([('KMeans', 'Label')])\n",
    "# deleting KMeans grouping if it already exists\n",
    "if ('KMeans', 'Label') in df.columns:\n",
    "    df = df.drop(columns=('KMeans', 'Label'))\n",
    "\n",
    "# join KMeans Label_DataFrame with the original Dataframe df\n",
    "df = df.join(labels)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf721d37-c72b-4057-9ee3-9ed266fec954",
   "metadata": {},
   "source": [
    "# Darstellen der KMeans-Ergebnisse\n",
    "Der folgende Codeblock erzeugt ein Mapping, ähnlich zu den bereits zuvor erstellten Maps für die mechanischen Daten. Zusätzlich werden die über die Gruppen gemittelten Werte für Härte und E-Modul in einem weiteren Plot angezeigt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a1650-4cb2-47f4-8b92-889eb9c1ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== change parameter from here ===#\n",
    "#marker options\n",
    "marker_shape = \">\" #<-- \"s\" for squares, \">\" for triangles\n",
    "marker_size = 85 # setting the size of the markers\n",
    "marker_tranparency = 0.75 # setting the transparency of the markers\n",
    "\n",
    "#choosing between ideal indent position and real indent positions\n",
    "indent_position = \"real\" # <-- \"real\" or \"ideal\"\n",
    "\n",
    "#change the colormap of the plots\n",
    "colormap = \"tab10\" #<-- \"tab10\", \"tab20\", \"colorblind\" \n",
    "\n",
    "#=========================#\n",
    "\n",
    "#=== dont change paramter from here ===#\n",
    "n_cluster_kmeans = df[(\"KMeans\",\"Label\")].nunique()+2\n",
    "#image size\n",
    "image_width_cm = 15 #change value to alter the image size\n",
    "image_height_cm = 15 # change value to alter the image size\n",
    "\n",
    "#Atomic Force Microscopy Mapping of Indentationmapping\n",
    "background_image = plt.imread(\"Data/Images/BackGround.png\")\n",
    "dx,dy = -2,-3.2 #parameter for adjusting the background image\n",
    "range_um = 50 # parameter for adjusting the background image\n",
    "\n",
    "# automatical column selection for indent position\n",
    "if indent_position == \"real\":\n",
    "    x = (\"x\",\"real\") # defining x axis\n",
    "    y = (\"y\",\"real\") # defining y axis\n",
    "elif indent_position ==\"ideal\":\n",
    "    x = (\"x\",\"absolut\") # defining x axis\n",
    "    y = (\"y\",\"absolut\") # defining x axis\n",
    "\n",
    "#creating a figure object\n",
    "fig, ax = plt.subplots(nrows = 1,\n",
    "                       ncols = 1, \n",
    "                       sharey=False)\n",
    "\n",
    "\n",
    "fig.set_dpi(600) # increasing the resolution of the plot\n",
    "fig.set_size_inches(image_width_cm/2.5,image_height_cm/2.54) #calcuating image size\n",
    "\n",
    "# Code for Mapping\n",
    "sns.scatterplot(data = df,\n",
    "                x = x,\n",
    "                y = y,\n",
    "                hue = (\"KMeans\",\"Label\"),\n",
    "                ax = ax,\n",
    "                marker = marker_shape, #square marker\n",
    "                palette = sns.color_palette(colormap,n_cluster_kmeans)[2:], # defining the color plaette\n",
    "                s = marker_size, # marker size\n",
    "                edgecolor = None, # remove the outline of the markers\n",
    "                alpha = marker_tranparency , # transparence of the markers infill\n",
    "               )\n",
    "\n",
    "ax.grid(False)\n",
    "if indent_position == \"real\":\n",
    "    ax.imshow(background_image,\n",
    "                 extent=[dx,range_um+dx,dy,range_um+dy],\n",
    "                 aspect='equal',\n",
    "                 zorder=-1,\n",
    "                 origin = \"upper\"\n",
    "                )\n",
    "\n",
    "ax.set_aspect(\"equal\") # ensure äquidistance on x and y axis\n",
    "sns.move_legend(loc = \"lower center\", bbox_to_anchor = (0.5,1), obj = ax) # move legend above the corresponding plots\n",
    "\n",
    "#Code for Catplot\n",
    "\n",
    "cols = [\n",
    "    (\"HARDNESS GPa\", \"mean\"),\n",
    "    (\"MODULUS GPa\", \"mean\"),\n",
    "    (\"S2overP\", \"mean\"),\n",
    "    (\"KMeans\", \"Label\"),\n",
    "]\n",
    "\n",
    "df_sel = df[cols].copy()\n",
    "df_sel.columns = [\"Hardness\", \"Modulus\", \"S2overP\", \"Cluster\"]\n",
    "\n",
    "df_long = df_sel.melt(\n",
    "    id_vars=\"Cluster\",\n",
    "    var_name=\"Property\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "g = sns.catplot(\n",
    "        data=df_long,\n",
    "        x=\"Cluster\",\n",
    "        y=\"Value\",\n",
    "        col=\"Property\",      # drei Plots nebeneinander\n",
    "        kind=\"violin\",          # Mittelwerte als Balken\n",
    "        sharey=False,\n",
    "        hue = \"Cluster\", # unterschiedliche Skalen erlaubt\n",
    "        palette = sns.color_palette(colormap,n_cluster_kmeans)[2:]\n",
    "        )\n",
    "g.figure.set_dpi(600)\n",
    "g.figure.set_size_inches(20/2.5,7/2.54)\n",
    "g._legend.remove()\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_axisbelow(True)     \n",
    "    ax.grid(True, linestyle=\"--\", alpha=1,linewidth = 2)\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d714830-e4ae-47a1-b0d7-5210eff829bd",
   "metadata": {},
   "source": [
    "Es sollte zu erkennen sein, dass sich die mechanischen Eigenschften der einzelnen Gruppen kaum voneinander unterscheiden. Demnach ist die Qualität des KMeans-Clusterings zu hinterfragen.\n",
    "\n",
    "Die nächsten Schritte befassen sich mit der Qualitätssteigerung von Cluster-Algorithmen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d64f71-73d7-4464-a57a-8744e4fe473d",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "Eine Möglichkeit, die Trennschärfe zwischen den Clustern zu erhöhen, ist die Durchführung einer **Principal Component Analysis** (PCA). Die PCA hilft dem Anwender bei der Beurteilung, welche Datenspalten _(also welches Feature-Set)_ an den Cluster-Algorithmus übergeben werden sollte. \n",
    "\n",
    "Eine weitere positive Eigenschaft der PCA ist die Reduzierung der Dimension des Feature-Sets. Je mehr Datenspalten an den Cluster-Algorithmus übergeben werden _(jede Spalte bedeutet eine zusätzliche Dimension)_, desto aufwendiger und ungenauer wird die Clusterbildung. Ab der vierten Dimension ist eine Visualisierung der Clusterbildung bereits nicht mehr möglich.  \n",
    "Mit der PCA kann analysiert werden, wie viele Dimensionen zur Darstellung der Datenabhängigkeiten notwendig sind. Anschließend werden die Daten auf neue Achsen transformiert. Hierbei handelt es sich um ein Feature-Set mit reduzierter Dimensionalität, aber identischer Aussagekraft bezüglich der Datenabhängigkeiten.\n",
    "\n",
    "Auch bei der PCA sollte man bei nicht physikalischen Größen (x-, y-Koordinaten) vorsichtig sein und sie besser nicht übergeben. Falls der Code im vorherigen Beispiel vor seiner Ausführung nicht kontrolliert wurde, wurden die Koordinaten dem KMeans-Algorithmus möglicherweise mit übergeben.\n",
    "\n",
    "**Hinweis:**  \n",
    "Physikalisch sinnvolle Materialkennwerte zur Phasentrennung sind zum Beispiel:  \n",
    "Härte, E-Modul sowie die quadrierte Steifigkeit, aufgetragen über die Last.\n",
    "\n",
    "- Mit `features` definieren Sie, welche Spalten an die PCA-Analyse übergeben werden sollen. Schließen Sie auf jeden Fall die x- und y-Koordinaten aus.  \n",
    "- Mit `n_components` legen Sie fest, welche Dimension der reduzierte Datenraum haben soll. Lassen Sie `n_components` am besten auf 2 stehen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14dd33-fb98-4731-95cb-59a336c741cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== change parameter ===#\n",
    "#selecting important columns for clustering\n",
    "features = df[[\n",
    "                (\"HARDNESS GPa\",\"mean\"),\n",
    "                (\"MODULUS GPa\",\"mean\"),\n",
    "                (\"S2overP\",\"mean\"),\n",
    "            \t(\"x\",\"real\"),\n",
    "                (\"y\",\"real\")\n",
    "                ]].copy()\n",
    "\n",
    "n_components = 2 #<-- determination of the dimension of the data space\n",
    "#=========================#\n",
    "\n",
    "#=== dont change paramter from here ===#\n",
    "\n",
    "#deleting indents with not data (Indent 15, Indent 67) \n",
    "features.dropna(inplace = True)\n",
    "\n",
    "# scale data very important for correct results!\n",
    "scaler = StandardScaler() \n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# PCA on scaled data\n",
    "pca = PCA(n_components=n_components) \n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6)) \n",
    "if X_pca.shape[1] == 3:\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c='steelblue', s=40)\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    ax.set_title('PCA Scatterplot (3D)')\n",
    "    plt.show()\n",
    "    print(\"Erklärte Varianzanteile:\", pca.explained_variance_ratio_)\n",
    "    loadings = pd.DataFrame(pca.components_.T, columns=['PCA1', 'PCA2',\"PCA3\"], index=features.columns ) \n",
    "    print(loadings)\n",
    "\n",
    "else:\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c='steelblue', s=40)\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('PCA Scatterplot (2D)')\n",
    "    plt.show()\n",
    "    print(\"Erklärte Varianzanteile:\", pca.explained_variance_ratio_)\n",
    "    loadings = pd.DataFrame(pca.components_.T, columns=['PC 1', 'PC 2'], index=features.columns ) \n",
    "    print(loadings)\n",
    "\n",
    "# deleting PCA columns in orignial data dataframe if present \n",
    "if 'PCA' in df.columns.get_level_values(0):\n",
    "    df = df.drop(columns='PCA', level=0)\n",
    "\n",
    "# make dataframe for PCA1 and PCA2 and maybe PCA3 axis\n",
    "pca_columns = [f'PC{i+1}' for i in range(X_pca.shape[1])]\n",
    "pca_df = pd.DataFrame(X_pca, columns=pca_columns, index=features.index)\n",
    "\n",
    "# transform to multi index column (\"PCA\",\"PC 1),(\"PC\",\"PC 2\"),...\n",
    "pca_df.columns = pd.MultiIndex.from_product([['PCA'], pca_columns])\n",
    "\n",
    "# join pca_df with orignal DataFrame df by Index \"Indent Nr\"\n",
    "df = df.join(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17dcf4-80b1-40d4-823d-2ba11e7c5645",
   "metadata": {},
   "source": [
    "Mit den Varianzanteilen lässt sich überprüfen, ob die Reduzierung der Dimensionalität des ursprünglichen Feature-Sets zielführend ist. Wenn die neuen Achsen des reduzierten Feature-Sets _(PC1 und PC2)_ mehr als 80 % der Datenabhängigkeiten beschreiben ist eine Erhöhung der Dimension um eine weitere Achse _(PC3)_ meistens nicht mehr sinvoll. Eine Erhöhung von `n_components` auf 3 würde keinen zusätzlichen Mehrwert liefern und die Dimensionalität des Feature-Sets unnötig erhöhen. \n",
    "\n",
    "Die Tabelle darunter zeigt, welche Datenabhängigkeiten auf welcher Achse aufgetragen sind und welche Relevanz eine mechanische Kenngröße für diese Achse hat _(hohe Zahlen = hohe Relevanz)_. Kenngrößen, die auf jeder Achse einen Wert nahe 0 besitzen, können und sollten aus dem Feature-Set ausgeschlossen werden.\n",
    "\n",
    "**Hinweis:**  \n",
    "\n",
    "Sollten Sie mit den dargestellten Ergebnissen nicht zufrieden sein – zum Beispiel wegen  \n",
    "- unnötiger PC-Achsen oder  \n",
    "- unnötiger Materialkennwerte –,  \n",
    "\n",
    "können Sie nachträglich `features` und `n_components` anpassen und den Code einfach erneut ausführen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e4faf-30dd-4f9e-b1c1-8e25569e57ff",
   "metadata": {},
   "source": [
    "# Bestimmen einer geeigneten Clusteranzahl\n",
    "\n",
    "Unüberwachte Cluster-Algorithmen wie **KMeans** oder das **Gaussian Mixture Model** benötigen die Angabe, wie viele Cluster erwartet werden. Doch nicht immer ist diese Anzahl bekannt _(vor allem, wenn man in den Daten auf der Suche nach Mustern ist)_.  \n",
    "\n",
    "Der **Silhouette Score** und der **Elbow-Plot** sind beides Hilfsmittel, um eine geeignete Anzahl an Clustern zu definieren. Bei beiden Ansätzen handelt es sich um Kontrollen, die im Grunde erst nach dem Clustering angewendet werden.\n",
    "\n",
    "Der folgende Codeblock führt nacheinander zehn KMeans-Algorithmen aus und erhöht in jedem Durchlauf die Clusteranzahl um 1. Anschließend werden für jede Variante der Silhouette Score und die Inertia _(Elbow-Plot)_ aufgezeichnet.\n",
    "\n",
    "**Silhouette Score:**  \n",
    "\n",
    "Der Silhouette Score bewertet, **wie gut ein Punkt zu seinem eigenen Cluster passt – im Vergleich zu anderen Clustern**. Er liegt zwischen –1 und +1:\n",
    "\n",
    "- **Nahe +1:** Punkt ist gut im eigenen Cluster platziert und weit von anderen Clustern entfernt → gute Trennung.  \n",
    "- **Nahe 0:** Punkt liegt zwischen zwei Clustern → keine klare Zuordnung.  \n",
    "- **Negativ:** Punkt ist vermutlich im falschen Cluster → schlechte Struktur.\n",
    "\n",
    "- **Interpretation:**  \n",
    "  Ein hoher Silhouette Score (nahe 1) spricht für eine sinnvolle Clusterstruktur.\n",
    "\n",
    "**Inertia (Elbow-Plot)**  \n",
    "\n",
    "Die Inertia misst die durchschnittliche Entfernung der Punkte zu ihren Clusterzentren. Niedrige Werte zeigen kompakte Cluster, sinken jedoch automatisch bei steigender Clusteranzahl, sodass Inertia allein nicht zur Bestimmung der optimalen Clusteranzahl ausreicht.  \n",
    "Im Elbow-Plot wird die Inertia gegen die Clusteranzahl aufgetragen; der „Knick“ _(falls überhaupt erkennbar)_ zeigt, ab wann zusätzliche Cluster nur noch eine geringe Verbesserung bringen.\n",
    "\n",
    "**Hinweis:**  \n",
    "Mit `feature_set` legen Sie fest, ob das dimensionsreduzierte PCA-Feature-Set oder das ursprüngliche Feature-Set verwendet werden soll. Da bereits eine PCA durchgeführt wurde, ist es empfehlenswert, `feature_set = \"PCA\"` zu wählen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181b75a-b594-429e-a7d4-7ae857227709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== Change from here ===#\n",
    "feature_set = \"PCA\" #<-- \"PCA\" or \"features\"\n",
    "#========================#\n",
    "\n",
    "#=== Dont change from here ===#\n",
    "max_number_cluster = 10\n",
    "silhouette_scores = []\n",
    "inertias = []\n",
    "ks = []\n",
    "\n",
    "# Select data basis\n",
    "if feature_set == 'PCA':\n",
    "    if (\"PCA\",\"PC1\") not in df.columns:\n",
    "        raise ValueError(f\"Für 'feature_set = PCA' bitte zuvor die PCA-Analyse (Code:Durchführen PCA) ausführen!\")\n",
    "    X = df['PCA'].dropna()\n",
    "elif feature_set == 'features':\n",
    "    X = features.copy()\n",
    "else:\n",
    "    raise ValueError(\"features_source must be 'PCA' or 'features'.\")\n",
    "\n",
    "for k in range(2,max_number_cluster):\n",
    "    kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    inertia = kmeans.inertia_\n",
    "    inertias.append(inertia)\n",
    "    ks.append(k)\n",
    "\n",
    "# Silhouette Score is only defined for k > 1\n",
    "    score = silhouette_score(X, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"k = {k}, Inertia = {inertia:.2f}, Silhouette Score = {score:.3f}\")\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "color1 = 'tab:blue'\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia (Elbow)', color=color1)\n",
    "ax1.plot(ks, inertias, marker='o', color=color1, label='Inertia')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "ax2 = ax1.twinx()  # second y-axis for Silhouette Score\n",
    "color2 = 'tab:green'\n",
    "ax2.set_ylabel('Silhouette Score', color=color2)\n",
    "ax2.plot(ks, silhouette_scores, marker='s', linestyle='--', color=color2, label='Silhouette Score')\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "plt.title('KMeans: Elbow Plot & Silhouette Score')\n",
    "fig.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36baf90d-f9f8-41de-bf8b-d25f3cac9605",
   "metadata": {},
   "source": [
    "Im obigen Plot sind der Elbow-Plot und der Silhouette Score überlagert in Abhängigkeit von der Clusteranzahl dargestellt. Beurteilen Sie anhand des Plots, welche Clustergröße für den KMeans-Algorithmus am besten geeignet ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5190f-29f3-4155-a906-df79d313e0f0",
   "metadata": {},
   "source": [
    "# Optimiertes Clustering nach KMeans\n",
    "\n",
    "Führen Sie den untenstehenden Code aus. Als Feature-Set werden automatisch die PC1- und PC2-Spalten des DataFrames aus der PCA verwendet.  \n",
    "Passen Sie `n_clusters` anhand der Auswertung des Silhouette Scores und des Elbow-Plots an.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa71276-e7a5-481d-9209-8dc15db03083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === change parameter from here ===#\n",
    "# KMeans Clustersize\n",
    "n_clusters = 4  # number of clusters\n",
    "\n",
    "# Plot Options\n",
    "#marker options\n",
    "marker_shape = \">\" #<-- \"s\" for squares, \">\" for triangles\n",
    "marker_size = 85 # setting the size of the markers\n",
    "marker_tranparency = 0.75 # setting the transparency of the markers\n",
    "\n",
    "#choosing between ideal indent position and real indent positions\n",
    "indent_position = \"real\" # <-- \"real\" or \"ideal\"\n",
    "\n",
    "#change the colormap of the plots\n",
    "colormap = \"tab10\" #<-- \"tab10\", \"tab20\", \"colorblind\" \n",
    "#=========================#\n",
    "\n",
    "#=== dont change paramter from here ===#\n",
    "\n",
    "#Code for KMeans\n",
    "feature_pca = df.xs(\"PCA\",axis=1,level=0).copy()\n",
    "# using the feature set defind\" \n",
    "X_kmeans = feature_pca.dropna()\n",
    "\n",
    "# KMeans calculations \n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=42)\n",
    "labels = kmeans.fit_predict(X_kmeans).astype(int)\n",
    "\n",
    "# using strings for labelings instaed of numbers\n",
    "#label_names = [f\"Cluster {i+1}\" for i in labels]\n",
    "labels = pd.DataFrame(labels, index=X_kmeans.index)\n",
    "\n",
    "# creating MultiIndex colum name for joining labels_df with df\n",
    "#labels_df.columns = pd.MultiIndex.from_tuples([('KMeans', 'Label')])\n",
    "labels.columns = pd.MultiIndex.from_tuples([('KMeans', 'Label')])\n",
    "# deleting KMeans grouping if it already exists\n",
    "if ('KMeans', 'Label') in df.columns:\n",
    "    df = df.drop(columns=('KMeans', 'Label'))\n",
    "\n",
    "# join KMeans Label_DataFrame with the original Dataframe df\n",
    "df = df.join(labels)\n",
    "\n",
    "#Code for plotting\n",
    "\n",
    "n_cluster_kmeans = df[(\"KMeans\",\"Label\")].nunique()+2\n",
    "\n",
    "#image size\n",
    "image_width_cm = 15 #change value to alter the image size\n",
    "image_height_cm = 15 # change value to alter the image size\n",
    "\n",
    "#Atomic Force Microscopy Mapping of Indentationmapping\n",
    "background_image = plt.imread(\"Data/Images/BackGround.png\")\n",
    "dx,dy = -2,-3.2 #parameter for adjusting the background image\n",
    "range_um = 50 # parameter for adjusting the background image\n",
    "\n",
    "# automatical column selection for indent position\n",
    "if indent_position == \"real\":\n",
    "    x = (\"x\",\"real\") # defining x axis\n",
    "    y = (\"y\",\"real\") # defining y axis\n",
    "elif indent_position ==\"ideal\":\n",
    "    x = (\"x\",\"absolut\") # defining x axis\n",
    "    y = (\"y\",\"absolut\") # defining x axis\n",
    "\n",
    "#creating a figure object\n",
    "fig_map_kmeans, ax = plt.subplots(nrows = 1,\n",
    "                       ncols = 1, \n",
    "                       sharey=False)\n",
    "\n",
    "\n",
    "fig_map_kmeans.set_dpi(600) # increasing the resolution of the plot\n",
    "fig_map_kmeans.set_size_inches(image_width_cm/2.5,image_height_cm/2.54) #calcuating image size\n",
    "\n",
    "# Code for Mapping\n",
    "map_kmeans = sns.scatterplot(data = df,\n",
    "                x = x,\n",
    "                y = y,\n",
    "                hue = (\"KMeans\",\"Label\"),\n",
    "                ax = ax,\n",
    "                marker = marker_shape, #square marker\n",
    "                palette = sns.color_palette(colormap,n_cluster_kmeans)[2:], # defining the color plaette\n",
    "                s = marker_size, # marker size\n",
    "                edgecolor = None, # remove the outline of the markers\n",
    "                alpha = marker_tranparency , # transparence of the markers infill\n",
    "               )\n",
    "\n",
    "ax.grid(False)\n",
    "if indent_position == \"real\":\n",
    "    ax.imshow(background_image,\n",
    "                 extent=[dx,range_um+dx,dy,range_um+dy],\n",
    "                 aspect='equal',\n",
    "                 zorder=-1,\n",
    "                 origin = \"upper\"\n",
    "                )\n",
    "\n",
    "ax.set_aspect(\"equal\") # ensure äquidistance on x and y axis\n",
    "sns.move_legend(loc = \"lower center\", bbox_to_anchor = (0.5,1), obj = ax) # move legend above the corresponding plots\n",
    "\n",
    "#Code for Catplot\n",
    "\n",
    "cols = [\n",
    "    (\"HARDNESS GPa\", \"mean\"),\n",
    "    (\"MODULUS GPa\", \"mean\"),\n",
    "    (\"S2overP\", \"mean\"),\n",
    "    (\"KMeans\", \"Label\"),\n",
    "]\n",
    "\n",
    "df_sel = df[cols].copy()\n",
    "df_sel.columns = [\"Hardness\", \"Modulus\", \"S2overP\", \"Cluster\"]\n",
    "\n",
    "df_long = df_sel.melt(\n",
    "    id_vars=\"Cluster\",\n",
    "    var_name=\"Property\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "Cat_kmeans = sns.catplot(\n",
    "        data=df_long,\n",
    "        x=\"Cluster\",\n",
    "        y=\"Value\",\n",
    "        col=\"Property\",      # drei Plots nebeneinander\n",
    "        kind=\"violin\",          # Mittelwerte als Balken\n",
    "        sharey=False,\n",
    "        hue = \"Cluster\", # unterschiedliche Skalen erlaubt\n",
    "        palette = sns.color_palette(colormap,n_cluster_kmeans)[2:]\n",
    "        )\n",
    "Cat_kmeans.figure.set_dpi(600)\n",
    "Cat_kmeans.figure.set_size_inches(20/2.5,7/2.54)\n",
    "Cat_kmeans._legend.remove()\n",
    "\n",
    "for ax in Cat_kmeans.axes.flat:\n",
    "    ax.set_axisbelow(True)     \n",
    "    ax.grid(True, linestyle=\"--\", alpha=1,linewidth = 2)\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630884a2-4a7b-44f0-905b-3cf2c290ca94",
   "metadata": {},
   "source": [
    "Betrachten Sie das Mapping und den Cluster-Vergleich darunter und vergleichen Sie die aktuellen Ergebnisse mit der unoptimierten KMeans-Analyse von zuvor.  \n",
    "Es sollte auffallen, dass die Cluster nun eine höhere Trennschärfe besitzen als zuvor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a6040-9db6-4fc4-9f27-949794a2e015",
   "metadata": {},
   "source": [
    "# Clustering nach Gaussian Mixture Model\n",
    "\n",
    "Nachdem Sie die Clusterbildung mit KMeans kennengelernt und optimiert haben, wollen wir nun einen anderen Ansatz betrachten: das **Gaussian Mixture Model (GMM)**.  \n",
    "Im Gegensatz zu KMeans, das die Cluster als gleichförmige Kugeln annimmt, geht GMM davon aus, dass die Daten aus **verschiedenen multivariaten Normalverteilungen** stammen. Dadurch können die Cluster **unterschiedliche Formen, Größen und Ausrichtungen** haben. Auch GMM gehört zum *unüberwachten Lernen* und erfordert die vorherige Festlegung der Clusteranzahl.  \n",
    "\n",
    "Durch Ausführen des folgenden Codeblocks werden die Daten des DataFrames analysiert und die Indents bezüglich ihrer mechanischen Kennwerte in Gruppen eingeteilt. Hierfür wird im Beispiel der **GMM-Algorithmus** verwendet.  \n",
    "\n",
    "**Ablauf von GMM**\n",
    "1. **Initialisierung:** Für jedes Cluster wird eine multivariate Normalverteilung (Mittelwert & Kovarianz) festgelegt.  \n",
    "2. **Wahrscheinlichkeitszuweisung:** Für jeden Datenpunkt wird die Wahrscheinlichkeit berechnet, zu jedem Cluster zu gehören.  \n",
    "3. **Parameteraktualisierung:** Mittelwerte, Kovarianzen und Gewichtungen der Cluster werden angepasst, um die **Gesamtlikelihood** der Daten zu maximieren.  \n",
    "4. **Iteration:** Schritte 2 und 3 wiederholen sich, bis die Parameter stabil bleiben oder ein Abbruchkriterium erreicht ist.  \n",
    "5. **Clusterzuweisung:** Jeder Datenpunkt wird optional dem Cluster mit der höchsten Wahrscheinlichkeit zugewiesen.  \n",
    "\n",
    "**Wichtige Parameter**\n",
    "- `n_components`: Anzahl der Cluster  \n",
    "- `feature_set`: Welche Spalten des DataFrames für die Gruppierung verwendet werden  \n",
    "\n",
    "**Hinweis**  \n",
    "Da GMM und KMeans unterschiedliche Ansätze verfolgen, ist es ratsam, für den GMM-Algorithmus die geeignete Clusteranzahl erneut zu bestimmen. **Dies wird im untenstehenden Codeblock ausgeführt.** Als Feature-Set wird das dimensionsreduzierte Feature-Set aus der PCA verwendet.\n",
    "\n",
    "**Beurteilung der Clusteranzahl**  \n",
    "\n",
    "Folgende Kriterien helfen bei der Entscheidung, wie viele Cluster sinnvoll sind:\n",
    "\n",
    "**Silhouette Score**  \n",
    "Siehe die Erklärung im Abschnitt „Bestimmung einer geeigneten Clusteranzahl“.  \n",
    "\n",
    "**BIC & AIC**  \n",
    "Informationskriterien, die Modellgüte und Komplexität abwägen:  \n",
    "- Kleinerer Wert → besser  \n",
    "- BIC bestraft komplexe Modelle stärker als AIC, daher bevorzugt BIC oft weniger Cluster  \n",
    "\n",
    "Optimal ist eine Clusterzahl, bei der BIC/AIC minimal sind und der Silhouette Score hoch ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e429b-9385-44a7-b674-ce6e0627629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Change from here === #\n",
    "feature_set = \"PCA\" #<-- \"PCA\" or \"features\"\n",
    "# ======================== #\n",
    "\n",
    "silhouette_scores = []\n",
    "neg_log_likelihoods = []\n",
    "bic_scores = []\n",
    "aic_scores = []\n",
    "ks = []\n",
    "\n",
    "# Select data basis\n",
    "if feature_set == 'PCA':\n",
    "    X = df['PCA'].dropna()\n",
    "elif feature_set == 'features':\n",
    "    X = features.copy()\n",
    "else:\n",
    "    raise ValueError(\"features_source must be 'PCA' or 'features'.\")\n",
    "\n",
    "# Compute metrics for different k\n",
    "for k in range(2, max_number_cluster):\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42, n_init=5)\n",
    "    gmm.fit(X)\n",
    "    labels = gmm.predict(X)\n",
    "    \n",
    "    neg_ll = -gmm.score(X) * len(X)\n",
    "    bic = gmm.bic(X)\n",
    "    aic = gmm.aic(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    \n",
    "    neg_log_likelihoods.append(neg_ll)\n",
    "    bic_scores.append(bic)\n",
    "    aic_scores.append(aic)\n",
    "    silhouette_scores.append(score)\n",
    "    ks.append(k)\n",
    "\n",
    "# === Plot 1: -Log-Likelihood + Silhouette ===\n",
    "fig, ax1 = plt.subplots(figsize=(9,5))\n",
    "\n",
    "color1 = 'tab:purple'\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('− Log-Likelihood', color=color1)\n",
    "ax1.plot(ks, neg_log_likelihoods, marker='o', color=color1, label='− Log-Likelihood')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'tab:green'\n",
    "ax2.set_ylabel('Silhouette Score', color=color2)\n",
    "ax2.plot(ks, silhouette_scores, marker='s', linestyle='--', color=color2, label='Silhouette Score')\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Combined legend\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.title('GMM: −Log-Likelihood & Silhouette Score')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Plot 2: BIC + AIC ===\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(ks, bic_scores, marker='x', linestyle='--', color='red', label='BIC')\n",
    "plt.plot(ks, aic_scores, marker='^', linestyle='--', color='orange', label='AIC')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Information Criteria')\n",
    "plt.title('GMM: BIC & AIC')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf24a43-bdbe-47a2-a773-be4552985644",
   "metadata": {},
   "source": [
    "Betrachten Sie die Kriterien-Plots zur Bestimmung der geeigneten Clusteranzahl für den GMM-Algorithmus und bestimmen Sie die geeignete Clusteranzahl.  \n",
    "\n",
    "Mit dem unteren Codeblock wird nun der GMM-Algorithmus ausgeführt, und die daraus resultierende Gruppierung in das DataFrame übernommen.\n",
    "\n",
    "**Hinweis:**  \n",
    "Vor der Ausführung des Codes überprüfen Sie, ob der Parameter `n_components` der korrekten Anzahl an GMM-Clustern entspricht, und ändern Sie den Wert gegebenenfalls.  \n",
    "\n",
    "Die anschließend ausgeführten Plots bilden eine Gegenüberstellung der KMeans- und GMM-Algorithmen. Die Daten werden nach den Labeln in den Spalten `(\"KMeans\",\"Label\")` und `(\"GMM\",\"Label\")` sortiert und auf unterschiedliche Weise geplottet.  \n",
    "\n",
    "Beurteilen Sie, wie relevant in diesem speziellen Fall die Auswahl des Cluster-Algorithmus ist:\n",
    "\n",
    "- Welche Auswirkung hat die Auswahl des Algorithmus auf die Clusteranzahl?  \n",
    "- Welchen Einfluss hat die Auswahl des Algorithmus auf die ermittelten mechanischen Eigenschaften der Cluster?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70587025-bf42-4e91-8179-9150638b0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === change parameter from here ===#\n",
    "# GMM Cluster number\n",
    "n_components = 4  # number of clusters\n",
    "\n",
    "# Plot Options\n",
    "marker_shape = \">\"  # \"<\" for triangles, \"s\" for squares\n",
    "marker_size = 40\n",
    "marker_transparency = 0.75\n",
    "\n",
    "# choosing between ideal indent position and real indent positions\n",
    "indent_position = \"real\"  # \"real\" or \"ideal\"\n",
    "\n",
    "# colormap\n",
    "colormap = \"tab10\"  # \"tab10\", \"tab20\", \"colorblind\"\n",
    "#=========================#\n",
    "\n",
    "#=== don't change from here ===#\n",
    "\n",
    "# the allowed shape of the clusters\n",
    "covariance_type = \"full\" #<-- full, tied, diag, spherical\n",
    "\n",
    "# --- Prepare feature set ---\n",
    "feature_pca = df.xs(\"PCA\", axis=1, level=0).copy()\n",
    "X_gmm = feature_pca.dropna()\n",
    "\n",
    "# --- Fit GMM ---\n",
    "gmm = GaussianMixture(n_components=n_components, random_state=42, n_init=5,covariance_type = covariance_type)\n",
    "labels = gmm.fit_predict(X_gmm).astype(int)\n",
    "\n",
    "# convert to DataFrame and MultiIndex column for joining\n",
    "labels = pd.DataFrame(labels, index=X_gmm.index)\n",
    "labels.columns = pd.MultiIndex.from_tuples([('GMM', 'Label')])\n",
    "\n",
    "# remove existing GMM column if exists\n",
    "if ('GMM', 'Label') in df.columns:\n",
    "    df = df.drop(columns=('GMM', 'Label'))\n",
    "\n",
    "# join labels with original df\n",
    "df = df.join(labels)\n",
    "\n",
    "# --- Scatterplot / Mapping ---\n",
    "\n",
    "n_clusters_kmeans = df[(\"KMeans\", \"Label\")].nunique() + 2\n",
    "n_clusters_gmm = df[(\"GMM\",\"Label\")].nunique() + 2\n",
    "\n",
    "\n",
    "image_width_cm = 15\n",
    "image_height_cm = 15\n",
    "background_image = plt.imread(\"Data/Images/BackGround.png\")\n",
    "dx, dy = -2, -3.2\n",
    "range_um = 50\n",
    "\n",
    "if indent_position == \"real\":\n",
    "    x = (\"x\",\"real\")\n",
    "    y = (\"y\",\"real\")\n",
    "elif indent_position == \"ideal\":\n",
    "    x = (\"x\",\"absolut\")\n",
    "    y = (\"y\",\"absolut\")\n",
    "\n",
    "fig_map, ax = plt.subplots(ncols=2,\n",
    "                           nrows=1,\n",
    "                          sharey=True)\n",
    "fig_map.set_dpi(600)\n",
    "fig_map.set_size_inches(image_width_cm/2.5, image_height_cm/2.54)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=(\"KMeans\",\"Label\"),\n",
    "    ax=ax[0],\n",
    "    marker=marker_shape,\n",
    "    palette=sns.color_palette(colormap,n_clusters_kmeans)[2:],\n",
    "    s=marker_size,\n",
    "    edgecolor=None,\n",
    "    alpha=marker_transparency\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if indent_position == \"real\":\n",
    "    ax[0].imshow(\n",
    "        background_image,\n",
    "        extent=[dx, range_um+dx, dy, range_um+dy],\n",
    "        aspect='equal',\n",
    "        zorder=-1,\n",
    "        origin=\"upper\"\n",
    "    )\n",
    "ax[0].set_axisbelow(True)\n",
    "ax[0].set_aspect(\"equal\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=(\"GMM\",\"Label\"),\n",
    "    ax=ax[1],\n",
    "    marker=marker_shape,\n",
    "    palette=sns.color_palette(colormap,n_clusters_gmm)[2:],\n",
    "    s=marker_size,\n",
    "    edgecolor=None,\n",
    "    alpha=marker_transparency\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if indent_position == \"real\":\n",
    "    ax[1].imshow(\n",
    "        background_image,\n",
    "        extent=[dx, range_um+dx, dy, range_um+dy],\n",
    "        aspect='equal',\n",
    "        zorder=-1,\n",
    "        origin=\"upper\"\n",
    "    )\n",
    "ax[1].set_axisbelow(True)\n",
    "ax[1].set_aspect(\"equal\")\n",
    "for item in ax:\n",
    "    sns.move_legend(loc=\"lower center\", bbox_to_anchor=(0.5,1), obj=item)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Spalten für Properties\n",
    "properties = [(\"HARDNESS GPa\",\"mean\"),(\"MODULUS GPa\",\"mean\"), (\"S2overP\",\"mean\")]\n",
    "n_props = len(properties)\n",
    "\n",
    "# Figure mit 2 Zeilen (KMeans, GMM) und n_props Spalten\n",
    "fig, axes = plt.subplots(nrows=2, ncols=n_props, figsize=(4*n_props, 8), sharey=False)\n",
    "\n",
    "# Farbpalette\n",
    "palette_kmeans = sns.color_palette(colormap,n_clusters_kmeans)[2:]\n",
    "palette_gmm = sns.color_palette(colormap,n_clusters_gmm)[2:]\n",
    "\n",
    "# --- Erste Zeile: KMeans ---\n",
    "for i, prop in enumerate(properties):\n",
    "\n",
    "    y = df[prop].dropna()\n",
    "    sns.violinplot(\n",
    "        data=df,\n",
    "        x=df[(\"KMeans\",\"Label\")],\n",
    "        y=y,\n",
    "        hue=df[(\"KMeans\",\"Label\")],\n",
    "        ax=axes[0, i],\n",
    "        palette=palette_kmeans,\n",
    "        split=False\n",
    "    )\n",
    "    axes[0, i].set_title(f\"{prop} (KMeans)\")\n",
    "    axes[0, i].tick_params(axis=\"x\", rotation=45)\n",
    "    axes[0, i].set_xlabel(\"\")\n",
    "    axes[0, i].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    axes[0, i].set_axisbelow(True)   \n",
    "    axes[0, i].legend_.remove()\n",
    "\n",
    "# --- Zweite Zeile: GMM ---\n",
    "for i, prop in enumerate(properties):\n",
    "    y = df[prop].dropna()\n",
    "    sns.violinplot(\n",
    "        data=df,\n",
    "        x=df[(\"GMM\",\"Label\")],\n",
    "        y=y,\n",
    "        hue=df[(\"GMM\",\"Label\")],\n",
    "        ax=axes[1, i],\n",
    "        palette=palette_gmm,\n",
    "        split=False\n",
    "    )\n",
    "    axes[1, i].set_title(f\"{prop} (GMM)\")\n",
    "    axes[1, i].tick_params(axis=\"x\", rotation=45)\n",
    "    axes[1, i].set_xlabel(\"\")\n",
    "    axes[1, i].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    axes[1, i].set_axisbelow(True)   \n",
    "    axes[1, i].legend_.remove()\n",
    "\n",
    "# Optional: globaler Titel\n",
    "fig.suptitle(\"Cluster Properties: KMeans vs GMM\", fontsize=16, y=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plot_dataframe(df, #<-- keep it \n",
    "               x=('PCA','PC1'), # choose x-axis\n",
    "               y=(\"PCA\",'PC2'), # choose y-axis\n",
    "               z = None, # choose z-axis or set it to None for 2D plot\n",
    "               hue=('KMeans','Label') # \n",
    "              ) \n",
    "\n",
    "plot_dataframe(df, #<-- keep it \n",
    "               x=('PCA','PC1'), # choose x-axis\n",
    "               y=(\"PCA\",'PC2'), # choose y-axis\n",
    "               z = None, # choose z-axis or set it to None for 2D plot\n",
    "               hue=('GMM','Label') # \n",
    "              ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
